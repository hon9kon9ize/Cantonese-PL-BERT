log_dir: "Checkpoint"
output_dir: "output"
mixed_precision: "bf16"
data_folder: "wikipedia_20220301.yue.processed"
batch_size: 256
log_interval: 100

dataset_params:
    tokenizer: "hon9kon9ize/bert-large-cantonese"
    token_separator: "[SEP]" # token used for phoneme separator (space)
    token_mask: "[MASK]" # token used for phoneme mask (M)
    word_separator: 102 # token used for word separator (<formula>)
    max_mel_length: 512 # max phoneme length
    word_mask_prob: 0.15 # probability to mask the entire word
    phoneme_mask_prob: 0.1 # probability to mask each phoneme
    replace_prob: 0.2 # probablity to replace phonemes

model_params:
    vocab_size: 477
    hidden_size: 768
    num_attention_heads: 12
    intermediate_size: 2048
    max_position_embeddings: 512
    num_hidden_layers: 12
    dropout: 0.1